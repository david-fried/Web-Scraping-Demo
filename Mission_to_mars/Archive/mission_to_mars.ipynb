{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup, Pandas, and Requests/Splinter\n",
    "# Used to complete scraping and analysis tasks\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import time\n",
    "from splinter import Browser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######Step 1 - Scraping #######\n",
    "# Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/).\n",
    "\n",
    "browser = init_browser()\n",
    "\n",
    "# URL of mars page\n",
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Scrape page into Soup\n",
    "html = browser.html\n",
    "\n",
    "soup = bs(browser.html, \"html.parser\")\n",
    "\n",
    "latest_title = soup.find('div', class_='list_text').find('div', class_='content_title').a.text\n",
    "\n",
    "latest_paragraph = soup.find('div', class_='list_text').find('div', class_=\"article_teaser_body\").text\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "browser = init_browser()\n",
    "\n",
    "url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "\n",
    "browser.visit(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "soup = bs(browser.html, \"html.parser\")\n",
    "\n",
    "full_img_button = browser.find_by_id('full_image')\n",
    "\n",
    "full_img_button.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "browser.find_by_css(\".buttons .button\").click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "browser.find_by_css(\".lede\").click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "featured_image = browser.url\n",
    "\n",
    "data = {\n",
    "    \"latest_title\": latest_title,\n",
    "    \"latest_paragraph\": latest_paragraph,\n",
    "    \"featured_image\": featured_image\n",
    "}\n",
    "\n",
    "# Close the browser after scraping\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latest_title': \"NASA Engineers Checking InSight's Weather Sensors\",\n",
       " 'latest_paragraph': 'An electronics issue is suspected to be preventing the sensors from sharing their data about Mars weather with the spacecraft.',\n",
       " 'featured_image': 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA19036_hires.jpg'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "\n",
    "# Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "\n",
    "# Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "# Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "# Make sure to save a complete url string for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mars Facts\n",
    "\n",
    "# Visit the Mars Facts webpage [here](https://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "url = \"https://space-facts.com/mars/\"\n",
    "\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Use Pandas to convert the data to a HTML table string\n",
    "df = tables[0]\n",
    "\n",
    "html_table = df.to_html()\n",
    "\n",
    "html_table\n",
    "\n",
    "html_table = html_table.replace('\\n', '')\n",
    "\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mars Hemispheres\n",
    "\n",
    "# Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "# You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "# Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "# Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "#Visit the USGS Astrogeology site to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "browser = init_browser()\n",
    "url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(url)\n",
    "html_hemispheres = browser.html\n",
    "soup = bs(html_hemispheres, 'html.parser')\n",
    "items = soup.find_all('div', class_='item')\n",
    "hemisphere_image_urls = []\n",
    "hemispheres_main_url = 'https://astrogeology.usgs.gov'\n",
    "for i in items: \n",
    "    title = i.find('h3').text\n",
    "    partial_img_url = i.find('a', class_='itemLink product-item')['href']e \n",
    "    browser.visit(hemispheres_main_url + partial_img_url)\n",
    "    partial_img_html = browser.html \n",
    "    soup = bs( partial_img_html, 'html.parser')\n",
    "    img_url = hemispheres_main_url + soup.find('img', class_='wide-image')['src']\n",
    "    hemisphere_image_urls.append({\"title\" : title, \"img_url\" : img_url})\n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######MongoDB and Flask Application #######\n",
    "\n",
    "### Use MongoDB with Flask templating to create a new HTML page that displays all of the information that was scraped from the URLs above.\n",
    "\n",
    "# Start by converting your Jupyter notebook into a Python script called `scrape_mars.py` with a function called `scrape` that will execute all of your scraping code from above and return one Python dictionary containing all of the scraped data.\n",
    "\n",
    "# Next, create a route called `/scrape` that will import your `scrape_mars.py` script and call your `scrape` function.\n",
    "\n",
    "# Store the return value in Mongo as a Python dictionary.\n",
    "\n",
    "# Create a root route `/` that will query your Mongo database and pass the mars data into an HTML template to display the data.\n",
    "\n",
    "# Create a template HTML file called `index.html` that will take the mars data dictionary and display all of the data in the appropriate HTML elements. Use the following as a guide for what the final product should look like, but feel free to create your own design."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
